{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section 1: Load datasets\n",
    "train_data = pd.read_csv('train.csv')\n",
    "test_data = pd.read_csv('test.csv')\n",
    "sample_submission = pd.read_csv('sample_submission.csv')\n",
    "\n",
    "# Section 2: Explore the dataset\n",
    "# print(\"Train Data Overview:\")\n",
    "# print(train_data.info())\n",
    "# print(train_data.head())\n",
    "# print(train_data.describe())\n",
    "\n",
    "# # Check for missing values\n",
    "# print(\"Missing Values:\")\n",
    "# print(train_data.isnull().sum())\n",
    "\n",
    "# Section 3: Preprocessing\n",
    "# Haversine function to calculate distance between two geo-coordinates\n",
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    R = 6371  # Radius of the Earth in kilometers\n",
    "    lat1, lon1, lat2, lon2 = map(np.radians, [lat1, lon1, lat2, lon2])\n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "    a = np.sin(dlat / 2.0)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon / 2.0)**2\n",
    "    c = 2 * np.arcsin(np.sqrt(a))\n",
    "    return R * c\n",
    "\n",
    "# Combine preprocessing for both train and test data\n",
    "def preprocess_data(data, is_train=True, fraud_counts=None):\n",
    "    if is_train:\n",
    "        # Group by `cc_num` and calculate fraud counts\n",
    "        fraud_counts = data.groupby(['cc_num', 'is_fraud']).size().unstack(fill_value=0).reset_index()\n",
    "        fraud_counts.columns = ['cc_num', 'is_fraud_0_count', 'is_fraud_1_count']\n",
    "        # Add a new column for fraud_score\n",
    "        fraud_counts['fraud_score'] = (fraud_counts['is_fraud_0_count'] * 10) - (fraud_counts['is_fraud_1_count'] * 50)\n",
    "\n",
    "    # Merge fraud counts into the data\n",
    "    data = data.merge(fraud_counts, on='cc_num', how='left')\n",
    "\n",
    "\n",
    "    # Convert dates to datetime\n",
    "    data['trans_date'] = pd.to_datetime(data['trans_date'], errors='coerce')\n",
    "    data['dob'] = pd.to_datetime(data['dob'], errors='coerce')\n",
    "    data['trans_time'] = pd.to_datetime(data['trans_time'], format='%H:%M:%S')\n",
    "\n",
    "    # Feature engineering:\n",
    "    data['age'] = (pd.Timestamp.now() - data['dob']).dt.days // 366\n",
    "    data['trans_hour'] = data['trans_time'].dt.hour\n",
    "    data['trans_minute'] = data['trans_time'].dt.minute\n",
    "    data['trans_second'] = data['trans_time'].dt.second\n",
    "    data['trans_time_seconds'] = data['trans_time'].dt.hour * 3600 + data['trans_time'].dt.minute * 60 + data['trans_time'].dt.second\n",
    "    data['seconds_from_midnight'] = 43200 - abs(43200 - data['trans_time_seconds'])\n",
    "    data['hours_from_midnight'] = 12 - abs(12 - data['trans_hour'])\n",
    "    data['day_of_week'] = data['trans_date'].dt.dayofweek\n",
    "\n",
    "    # Feature engineering: Calculate distance between cardholder and merchant\n",
    "    data['haversine_distance'] = haversine(\n",
    "        data['lat'], data['long'], data['merch_lat'], data['merch_long']\n",
    "    )\n",
    "\n",
    "    # Drop unnecessary columns, including raw datetime and location fields\n",
    "    columns_to_drop = ['id', 'trans_num', 'cc_num', 'first', 'last', 'street', 'dob', 'trans_date', 'city', 'zip', 'city_pop']\n",
    "    columns_to_drop += ['lat', 'long', 'merch_lat', 'merch_long']\n",
    "    columns_to_drop += ['trans_time', 'trans_hour', 'trans_minute', 'trans_second', 'trans_time_seconds', 'hours_from_midnight']\n",
    "    columns_to_drop += ['fraud_score', 'is_fraud_0_count', 'is_fraud_1_count']\n",
    "    # columns_to_drop += ['fraud_score']\n",
    "    data = data.drop(columns=columns_to_drop, axis=1)\n",
    "\n",
    "    # Convert categorical columns to dummy variables\n",
    "    categorical_cols = ['category', 'gender', 'state', 'job', 'merchant']\n",
    "    data = pd.get_dummies(data, columns=categorical_cols, drop_first=True)\n",
    "\n",
    "    # Ensure all remaining columns are numeric\n",
    "    data = data.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "    if is_train:\n",
    "        return data, fraud_counts\n",
    "    else:\n",
    "        return data\n",
    "\n",
    "# Preprocess train data\n",
    "train_data, fraud_counts = preprocess_data(train_data, is_train=True)\n",
    "\n",
    "# Separate features and target\n",
    "X = train_data.drop('is_fraud', axis=1)\n",
    "y = train_data['is_fraud']\n",
    "\n",
    "# Preprocess test data\n",
    "test_data = preprocess_data(test_data, is_train=False, fraud_counts=fraud_counts)\n",
    "\n",
    "# Ensure the test data has the same columns as training data\n",
    "missing_cols = set(X.columns) - set(test_data.columns)\n",
    "for col in missing_cols:\n",
    "    test_data[col] = 0\n",
    "test_data = test_data[X.columns]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['unix_time', 'amt', 'is_fraud', 'age', 'seconds_from_midnight',\n",
      "       'day_of_week', 'haversine_distance', 'category_food_dining',\n",
      "       'category_gas_transport', 'category_grocery_net',\n",
      "       ...\n",
      "       'merchant_fraud_Yost, Schamberger and Windler',\n",
      "       'merchant_fraud_Yost-Rogahn', 'merchant_fraud_Zboncak LLC',\n",
      "       'merchant_fraud_Zboncak Ltd',\n",
      "       'merchant_fraud_Zboncak, Rowe and Murazik',\n",
      "       'merchant_fraud_Zemlak Group',\n",
      "       'merchant_fraud_Zemlak, Tillman and Cremin',\n",
      "       'merchant_fraud_Ziemann-Waters',\n",
      "       'merchant_fraud_Zieme, Bode and Dooley', 'merchant_fraud_Zulauf LLC'],\n",
      "      dtype='object', length=1401)\n",
      "Index(['unix_time', 'amt', 'age', 'seconds_from_midnight', 'day_of_week',\n",
      "       'haversine_distance', 'category_food_dining', 'category_gas_transport',\n",
      "       'category_grocery_net', 'category_grocery_pos',\n",
      "       ...\n",
      "       'merchant_fraud_Yost, Schamberger and Windler',\n",
      "       'merchant_fraud_Yost-Rogahn', 'merchant_fraud_Zboncak LLC',\n",
      "       'merchant_fraud_Zboncak Ltd',\n",
      "       'merchant_fraud_Zboncak, Rowe and Murazik',\n",
      "       'merchant_fraud_Zemlak Group',\n",
      "       'merchant_fraud_Zemlak, Tillman and Cremin',\n",
      "       'merchant_fraud_Ziemann-Waters',\n",
      "       'merchant_fraud_Zieme, Bode and Dooley', 'merchant_fraud_Zulauf LLC'],\n",
      "      dtype='object', length=1400)\n"
     ]
    }
   ],
   "source": [
    "print(train_data.columns)\n",
    "print(test_data.columns)\n",
    "# print(train_data.head())\n",
    "\n",
    "# print(test_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = train_data.groupby('is_fraud')['fraud_score'].mean()\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AnalyzeFeature(df, feature):\n",
    "    # Group by 'Score' and calculate the average of the specified feature for each score\n",
    "    avg_feature_by_score = df.groupby('is_fraud')[feature].mean()\n",
    "\n",
    "    print(f\"Average {feature} by Score:\")\n",
    "    print(avg_feature_by_score)\n",
    "\n",
    "    # Correlation between the specified feature and 'Score'\n",
    "    correlation = df[[feature, 'is_fraud']].corr()\n",
    "\n",
    "    print(f\"Correlation between {feature} and Score:\")\n",
    "    print(correlation)\n",
    "    \n",
    "Features = ['fraud_score', 'is_fraud_1_count', 'is_fraud_0_count']\n",
    "for ft in Features:\n",
    "  AnalyzeFeature(train_data, ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99     65621\n",
      "           1       0.97      0.93      0.95      8520\n",
      "\n",
      "    accuracy                           0.99     74141\n",
      "   macro avg       0.98      0.96      0.97     74141\n",
      "weighted avg       0.99      0.99      0.99     74141\n",
      "\n",
      "Confusion Matrix:\n",
      "[[65416   205]\n",
      " [  602  7918]]\n",
      "F1 Score: 0.9515111458270744\n",
      "ROC AUC Score: 0.9971625205431704\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Section 4: Split the data\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Section 5: Baseline model: Random Forest Classifier\n",
    "rf_model = RandomForestClassifier(random_state=0, n_jobs=2)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Section 6: Predictions and evaluation\n",
    "y_pred = rf_model.predict(X_val)\n",
    "y_pred_proba = rf_model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_val, y_pred))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_val, y_pred))\n",
    "\n",
    "print(\"F1 Score:\", f1_score(y_val, y_pred))\n",
    "\n",
    "print(\"ROC AUC Score:\", roc_auc_score(y_val, y_pred_proba))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get feature importances from the Random Forest model\n",
    "feature_importances = rf_model.feature_importances_\n",
    "\n",
    "# Create a DataFrame for better visualization\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': X_train.columns,\n",
    "    'Importance': feature_importances\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Print the feature importance rankings\n",
    "print(\"Feature Importance:\")\n",
    "print(importance_df)\n",
    "\n",
    "# Plot feature importances\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(importance_df['Feature'], importance_df['Importance'])\n",
    "plt.gca().invert_yaxis()  # Flip the y-axis to have the highest importance at the top\n",
    "plt.title(\"Feature Importances\")\n",
    "plt.xlabel(\"Importance Score\")\n",
    "plt.ylabel(\"Features\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99     65592\n",
      "           1       0.99      0.86      0.92      8549\n",
      "\n",
      "    accuracy                           0.98     74141\n",
      "   macro avg       0.99      0.93      0.95     74141\n",
      "weighted avg       0.98      0.98      0.98     74141\n",
      "\n",
      "Confusion Matrix:\n",
      "[[65547    45]\n",
      " [ 1235  7314]]\n",
      "F1 Score: 0.919537339703294\n"
     ]
    }
   ],
   "source": [
    "m4 = ExtraTreesClassifier(random_state=0, n_jobs=3, criterion='entropy')\n",
    "m4.fit(X_train, y_train)\n",
    "\n",
    "# Section 6: Predictions and evaluation\n",
    "y4 = m4.predict(X_val)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_val, y4))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_val, y4))\n",
    "\n",
    "print(\"F1 Score:\", f1_score(y_val, y4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file created: submission.csv\n"
     ]
    }
   ],
   "source": [
    "# Section 7: Make predictions on the test dataset\n",
    "test_predictions = rf_model.predict(test_data)\n",
    "\n",
    "# Section 8: Create a submission file\n",
    "submission = pd.DataFrame({'id': sample_submission['id'], 'is_fraud': test_predictions})\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "\n",
    "print(\"Submission file created: submission.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
